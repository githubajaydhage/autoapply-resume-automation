# ‚ö° AGGRESSIVE JOB HUNTING - Run every 3 hours
# Maximize applications and interview chances

name: ‚ö° Fast Track to Interviews

on:
  # Manual trigger with options
  workflow_dispatch:
    inputs:
      max_applications:
        description: 'Max applications to send'
        required: false
        default: '30'
      run_mode:
        description: 'Run mode'
        required: false
        default: 'full'
        type: choice
        options:
          - full
          - scrape_only
          - apply_only
  
  # Run every 3 hours during business hours
  schedule:
    - cron: '0 6,9,12,15,18 * * 1-5'  # Mon-Fri, every 3 hours

# Cancel any in-progress workflow when a new one starts or when cancelled from UI
concurrency:
  group: fast-track-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # Phase 1: Scrape jobs from ALL sources
  scrape-all-sources:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: ${{ github.event.inputs.run_mode != 'apply_only' }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: üîç Scrape jobs - Standard sources
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          echo "=== Scraping from standard sources ==="
          python scripts/scrape_jobs.py || true
          python scripts/reliable_job_scraper.py || true
      
      - name: üîç Scrape jobs - Bulletproof engine
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          echo "=== Running bulletproof engine (15+ sources) ==="
          python scripts/bulletproof_job_engine.py || true
      
      - name: üîç Scrape jobs - Real-time alerts
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          echo "=== Getting real-time job alerts ==="
          python scripts/realtime_job_alerts.py || true
      
      - name: üìä Count jobs found
        run: |
          if [ -f data/jobs_today.csv ]; then
            echo "Jobs found: $(wc -l < data/jobs_today.csv)"
            head -20 data/jobs_today.csv
          fi
      
      - name: üíæ Upload job data
        uses: actions/upload-artifact@v4
        with:
          name: jobs-data
          path: data/
          retention-days: 7

  # Phase 2: Find HR emails
  discover-hr-emails:
    needs: scrape-all-sources
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: always() && (github.event.inputs.run_mode != 'apply_only')
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: üì• Download job data
        uses: actions/download-artifact@v4
        with:
          name: jobs-data
          path: data/
        continue-on-error: true
      
      - name: üìß Find HR emails - Curated database
        run: |
          echo "=== Getting curated HR emails ==="
          python -c "from scripts.curated_hr_database import get_all_hr_emails; print(f'Curated emails: {len(get_all_hr_emails())}')" || true
      
      - name: üìß Find HR emails - Advanced discovery (FAST - 10 companies max)
        env:
          HUNTER_API_KEY: ${{ secrets.HUNTER_API_KEY }}
          MAX_DISCOVERY_COMPANIES: '10'
        run: |
          echo "=== Running advanced HR discovery (limited to 10 NEW companies) ==="
          python scripts/advanced_hr_discovery.py || true
      
      - name: üìß Find HR emails - Scraper
        run: |
          echo "=== Scraping HR emails ==="
          python scripts/email_scraper.py || true
          python scripts/hr_email_finder.py || true
      
      - name: üíæ Upload HR data
        uses: actions/upload-artifact@v4
        with:
          name: hr-data
          path: data/
          retention-days: 7

  # Phase 3: SEND APPLICATIONS!
  send-applications:
    needs: discover-hr-emails
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: üì• Download all data
        uses: actions/download-artifact@v4
        with:
          path: data/
          merge-multiple: true
        continue-on-error: true
      
      - name: üì§ SEND MAXIMUM APPLICATIONS!
        env:
          SENDER_EMAIL: ${{ secrets.GMAIL_USER }}
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          SENDER_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          APPLICANT_NAME: ${{ secrets.APPLICANT_NAME }}
          APPLICANT_EMAIL: ${{ secrets.APPLICANT_EMAIL }}
          APPLICANT_PHONE: ${{ secrets.APPLICANT_PHONE }}
          APPLICANT_LINKEDIN: ${{ secrets.APPLICANT_LINKEDIN }}
          YEARS_EXPERIENCE: ${{ secrets.YEARS_EXPERIENCE }}
          APPLICANT_SKILLS: ${{ secrets.APPLICANT_SKILLS }}
          APPLICANT_TARGET_ROLE: ${{ secrets.APPLICANT_TARGET_ROLE }}
          RESUME_PATH: 'resumes/resume.pdf'
          MAX_EMAILS_PER_RUN: ${{ github.event.inputs.max_applications || '30' }}
        run: |
          echo "=== SENDING APPLICATIONS ==="
          echo "Max emails: $MAX_EMAILS_PER_RUN"
          
          # Method 1: Max applications sender
          python scripts/max_applications_sender.py || true
          
          # Method 2: Standard email sender as backup
          python scripts/email_sender.py || true
      
      - name: üì§ Send via referral system
        env:
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          SENDER_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          echo "=== Sending referral requests ==="
          python scripts/referral_system.py || true
      
      - name: üìä Application stats
        run: |
          echo "=== APPLICATION SUMMARY ==="
          if [ -f data/applied_log.csv ]; then
            echo "Total applications: $(wc -l < data/applied_log.csv)"
            echo ""
            echo "Recent applications:"
            tail -10 data/applied_log.csv
          fi
      
      - name: üíæ Upload application log
        uses: actions/upload-artifact@v4
        with:
          name: application-log
          path: data/applied_log.csv
          retention-days: 30

  # Phase 4: Follow-ups (important for getting responses!)
  send-followups:
    needs: send-applications
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: üì• Download application log
        uses: actions/download-artifact@v4
        with:
          name: application-log
          path: data/
        continue-on-error: true
      
      - name: üîî Send follow-ups
        env:
          GMAIL_USER: ${{ secrets.GMAIL_USER }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          APPLICANT_NAME: ${{ secrets.APPLICANT_NAME }}
        run: |
          echo "=== Sending follow-up emails ==="
          python scripts/followup_sender.py || true

  # Phase 5: Notify me!
  notify-success:
    needs: [send-applications, send-followups]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python 3.9
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: üì• Download all data
        uses: actions/download-artifact@v4
        with:
          path: data/
          merge-multiple: true
        continue-on-error: true
      
      - name: üì± Send Slack notification
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: python scripts/slack_notifier.py || true
        continue-on-error: true
      
      - name: üì± Send mobile alerts
        env:
          PUSHOVER_USER_KEY: ${{ secrets.PUSHOVER_USER_KEY }}
          PUSHOVER_API_TOKEN: ${{ secrets.PUSHOVER_API_TOKEN }}
          TWILIO_ACCOUNT_SID: ${{ secrets.TWILIO_ACCOUNT_SID }}
          TWILIO_AUTH_TOKEN: ${{ secrets.TWILIO_AUTH_TOKEN }}
          TWILIO_PHONE_FROM: ${{ secrets.TWILIO_PHONE_FROM }}
          TWILIO_PHONE_TO: ${{ secrets.TWILIO_PHONE_TO }}
        run: python scripts/mobile_alerts.py || true
        continue-on-error: true
      
      - name: üìä Final Summary
        run: |
          echo "=============================================="
          echo "‚ö° FAST TRACK TO INTERVIEWS - COMPLETE"
          echo "=============================================="
          echo ""
          echo "üìÅ Files generated:"
          ls -la data/ || true
          echo ""
          if [ -f data/jobs_today.csv ]; then
            echo "üìã Jobs scraped: $(wc -l < data/jobs_today.csv)"
          fi
          if [ -f data/applied_log.csv ]; then
            echo "üìß Applications sent: $(wc -l < data/applied_log.csv)"
          fi
          echo ""
          echo "üéØ Next run: Check GitHub Actions schedule"
          echo "=============================================="
