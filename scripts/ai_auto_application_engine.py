"""
ğŸ¤– AI AUTO-APPLICATION ENGINE

Fully automated job application system using AI to:
1. Find and score job opportunities 
2. Generate personalized applications
3. Optimize timing and targeting
4. Auto-apply with intelligent decision making
5. Track and learn from results

Author: AutoApply Automation
"""

import os
import sys
import logging
import pandas as pd
import json
import re
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from scripts.enhanced_job_scraper import EnhancedJobScraper
    from scripts.ai_hr_email_discovery import AIHREmailDiscovery
    from scripts.email_sender import PersonalizedEmailSender
    from scripts.ai_smart_linkedin_scraper import AILinkedInScraper
    from scripts.free_ai_providers import get_ai
    AI_AVAILABLE = True
except ImportError as e:
    logging.error(f"Required modules not available: {e}")
    AI_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')


class AIAutoApplicationEngine:
    """
    ğŸ¤– Fully automated AI-powered job application system.
    """
    
    def __init__(self, max_applications_per_day: int = 30):
        if not AI_AVAILABLE:
            raise Exception("AI modules not available - check installation")
        
        self.base_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.data_path = os.path.join(self.base_path, 'data')
        
        # Initialize AI components
        self.ai = get_ai()
        self.job_scraper = EnhancedJobScraper()
        self.email_discovery = AIHREmailDiscovery()
        self.email_sender = PersonalizedEmailSender()
        self.linkedin_scraper = AILinkedInScraper()
        
        # Configuration
        self.max_applications_per_day = max_applications_per_day
        self.min_job_relevance_score = 75  # Only apply to highly relevant jobs
        self.min_email_confidence = 60     # Only use confident email predictions
        
        # Tracking
        self.session_stats = {
            'jobs_analyzed': 0,
            'high_relevance_jobs': 0,
            'emails_discovered': 0,
            'applications_sent': 0,
            'ai_decisions': 0,
            'start_time': datetime.now()
        }
        
        logging.info("ğŸ¤– AI AUTO-APPLICATION ENGINE initialized")
        logging.info(f"   Max applications/day: {max_applications_per_day}")
        logging.info(f"   Min relevance score: {self.min_job_relevance_score}%")
        logging.info(f"   Min email confidence: {self.min_email_confidence}%")
    
    def run_automated_application_campaign(self, target_keywords: List[str] = None, target_companies: List[str] = None) -> Dict:
        """
        ğŸš€ Run complete automated job application campaign.
        
        This is the main function that orchestrates the entire process.
        """
        logging.info("ğŸš€ STARTING AI-POWERED AUTO-APPLICATION CAMPAIGN")
        logging.info("="*70)
        
        results = {
            'campaign_start': datetime.now().isoformat(),
            'phases': {},
            'final_stats': {}
        }
        
        # PHASE 1: AI Job Discovery & Scoring
        logging.info("ğŸ” PHASE 1: AI Job Discovery & Relevance Scoring")
        try:
            jobs_df = self._ai_job_discovery_phase()
            results['phases']['job_discovery'] = {
                'total_jobs': len(jobs_df) if jobs_df is not None else 0,
                'high_relevance_jobs': len(jobs_df[jobs_df['ai_relevance_score'] >= self.min_job_relevance_score]) if jobs_df is not None and not jobs_df.empty else 0
            }
            
            if jobs_df is None or jobs_df.empty:
                logging.warning("âŒ No jobs found - ending campaign")
                return results
                
        except Exception as e:
            logging.error(f"âŒ Job discovery failed: {e}")
            results['phases']['job_discovery'] = {'error': str(e)}
            return results
        
        # PHASE 2: AI Email Discovery & Validation
        logging.info("\nğŸ“§ PHASE 2: AI Email Discovery & Validation")
        try:
            email_results = self._ai_email_discovery_phase(jobs_df)
            results['phases']['email_discovery'] = email_results
        except Exception as e:
            logging.error(f"âŒ Email discovery failed: {e}")
            results['phases']['email_discovery'] = {'error': str(e)}
        
        # PHASE 3: AI Application Generation & Sending
        logging.info("\nâœ‰ï¸ PHASE 3: AI Application Generation & Auto-Sending")
        try:
            application_results = self._ai_application_phase(jobs_df)
            results['phases']['applications'] = application_results
        except Exception as e:
            logging.error(f"âŒ Application phase failed: {e}")
            results['phases']['applications'] = {'error': str(e)}
        
        # PHASE 4: AI Analysis & Learning
        logging.info("\nğŸ“Š PHASE 4: AI Analysis & Optimization")
        try:
            analysis_results = self._ai_analysis_phase()
            results['phases']['analysis'] = analysis_results
        except Exception as e:
            logging.error(f"âŒ Analysis phase failed: {e}")
            results['phases']['analysis'] = {'error': str(e)}
        
        # Final Results
        results['final_stats'] = self.session_stats
        results['campaign_duration'] = str(datetime.now() - self.session_stats['start_time'])
        
        # Save comprehensive results
        self._save_campaign_results(results)
        
        # Generate summary report
        summary = self._generate_campaign_summary(results)
        logging.info(summary)
        
        return results
    
    def _ai_job_discovery_phase(self) -> pd.DataFrame:
        """Phase 1: Discover and score jobs with AI."""
        logging.info("ğŸ” Running AI-enhanced job scraping...")
        
        # Use enhanced job scraper with AI
        jobs_df = self.job_scraper.scrape_all()
        
        if jobs_df.empty:
            return None
        
        # AI enhance the job data
        jobs_df = self.job_scraper.ai_enhance_job_data(jobs_df, max_jobs=50)
        
        # Filter to high-relevance jobs only
        high_relevance_df = jobs_df[jobs_df['ai_relevance_score'] >= self.min_job_relevance_score]
        
        self.session_stats['jobs_analyzed'] = len(jobs_df)
        self.session_stats['high_relevance_jobs'] = len(high_relevance_df)
        
        logging.info(f"âœ… Jobs analyzed: {len(jobs_df)}")
        logging.info(f"âœ… High-relevance jobs: {len(high_relevance_df)}")
        
        return jobs_df.sort_values('ai_relevance_score', ascending=False)
    
    def _ai_email_discovery_phase(self, jobs_df: pd.DataFrame) -> Dict:
        """Phase 2: Discover HR emails using AI."""
        top_companies = jobs_df['company'].head(20).unique().tolist()
        
        discovered_emails = []
        email_stats = {'total_discovered': 0, 'high_confidence': 0, 'companies_processed': 0}
        
        for company in top_companies:
            try:
                # Get AI company research
                company_research = self.email_discovery.ai_research_company(company)
                
                # Generate smart email patterns
                email_patterns = self.email_discovery.generate_hr_emails_for_company(
                    company, 
                    industry=company_research.get('industry'),
                    company_size=company_research.get('size')
                )
                
                for pattern in email_patterns:
                    discovered_emails.append({
                        'company': company,
                        'email': pattern['email'],
                        'confidence': pattern['confidence'],
                        'source': pattern['source']
                    })
                
                email_stats['companies_processed'] += 1
                
            except Exception as e:
                logging.debug(f"Email discovery failed for {company}: {e}")
                continue
        
        # Filter to high-confidence emails
        high_confidence_emails = [e for e in discovered_emails if self._get_confidence_score(e['confidence']) >= self.min_email_confidence]
        
        email_stats['total_discovered'] = len(discovered_emails)
        email_stats['high_confidence'] = len(high_confidence_emails)
        self.session_stats['emails_discovered'] = len(discovered_emails)
        
        logging.info(f"âœ… Emails discovered: {email_stats['total_discovered']}")
        logging.info(f"âœ… High-confidence emails: {email_stats['high_confidence']}")
        
        return email_stats
    
    def _ai_application_phase(self, jobs_df: pd.DataFrame) -> Dict:
        """Phase 3: Generate and send AI-powered applications."""
        application_stats = {'attempted': 0, 'sent': 0, 'skipped': 0, 'ai_optimized': 0}
        
        # Focus on highest-scoring jobs
        top_jobs = jobs_df[jobs_df['ai_relevance_score'] >= self.min_job_relevance_score].head(self.max_applications_per_day)
        
        for _, job in top_jobs.iterrows():
            try:
                company = job['company']
                job_title = job['title']
                
                # AI-powered email discovery for this specific company
                email_patterns = self.email_discovery.generate_hr_emails_for_company(company)
                
                # Find the best email for this company
                best_email = self._select_best_email(email_patterns)
                
                if not best_email:
                    application_stats['skipped'] += 1
                    continue
                
                # Use AI-enhanced email sender
                success = self.email_sender.send_email(
                    recipient_email=best_email['email'],
                    company=company,
                    job_title=job_title,
                    job_url=job.get('url', '')
                )
                
                application_stats['attempted'] += 1
                
                if success:
                    application_stats['sent'] += 1
                    application_stats['ai_optimized'] += 1
                    logging.info(f"âœ… AI Application sent: {company} - {job_title}")
                else:
                    application_stats['skipped'] += 1
                
                # Rate limiting
                time.sleep(2)
                
            except Exception as e:
                logging.debug(f"Application failed for {job['company']}: {e}")
                application_stats['skipped'] += 1
                continue
        
        self.session_stats['applications_sent'] = application_stats['sent']
        
        logging.info(f"âœ… Applications sent: {application_stats['sent']}/{application_stats['attempted']}")
        
        return application_stats
    
    def _ai_analysis_phase(self) -> Dict:
        """Phase 4: AI-powered analysis and learning."""
        try:
            if not self.ai:
                return {'error': 'AI not available'}
            
            # Analyze campaign performance
            prompt = f"""Campaign Performance Analysis:

CAMPAIGN STATS:
- Jobs Analyzed: {self.session_stats['jobs_analyzed']}
- High-Relevance Jobs: {self.session_stats['high_relevance_jobs']}
- Emails Discovered: {self.session_stats['emails_discovered']}
- Applications Sent: {self.session_stats['applications_sent']}

Provide insights and optimization recommendations:
1. Campaign effectiveness score (0-100)
2. Key success factors
3. Areas for improvement
4. Next campaign recommendations

Respond in JSON:
{{
  "effectiveness_score": 85,
  "success_factors": ["factor1", "factor2"],
  "improvements": ["improvement1", "improvement2"],  
  "next_campaign": "recommendations for next run",
  "estimated_response_rate": 15,
  "confidence_level": "high"
}}"""
            
            ai_response = self.ai.generate(prompt, max_tokens=400)
            if ai_response:
                try:
                    import json
                    json_match = re.search(r'\\{.*\\}', ai_response, re.DOTALL)
                    if json_match:
                        analysis = json.loads(json_match.group())
                        logging.info(f"ğŸ¤– AI Campaign Analysis: {analysis.get('effectiveness_score', 'unknown')}% effective")
                        return analysis
                except:
                    pass
            
            # Fallback analysis
            effectiveness = min(90, (self.session_stats['applications_sent'] * 10))
            return {
                'effectiveness_score': effectiveness,
                'success_factors': ['AI job scoring', 'Automated targeting'],
                'improvements': ['Increase job sources', 'Optimize timing'],
                'estimated_response_rate': max(5, min(20, effectiveness // 5))
            }
            
        except Exception as e:
            logging.debug(f"AI analysis failed: {e}")
            return {'error': str(e)}
    
    def _get_confidence_score(self, confidence_level: str) -> int:
        """Convert confidence level to numeric score."""
        confidence_map = {
            'ai_high': 90,
            'high': 80,
            'medium': 60,
            'low': 40,
            'ai_generated': 85
        }
        return confidence_map.get(confidence_level, 50)
    
    def _select_best_email(self, email_patterns: List[Dict]) -> Dict:
        """Select the best email from patterns based on confidence."""
        if not email_patterns:
            return None
        
        # Sort by confidence score
        sorted_emails = sorted(email_patterns, key=lambda x: self._get_confidence_score(x['confidence']), reverse=True)
        
        # Return highest confidence email
        return sorted_emails[0] if sorted_emails else None
    
    def _save_campaign_results(self, results: Dict):
        """Save detailed campaign results."""
        results_file = os.path.join(self.data_path, 'ai_auto_application_results.json')
        
        try:
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            logging.info(f"ğŸ’¾ Campaign results saved to {results_file}")
        except Exception as e:
            logging.warning(f"Failed to save campaign results: {e}")
    
    def _generate_campaign_summary(self, results: Dict) -> str:
        """Generate campaign summary report."""
        stats = results['final_stats']
        
        summary = f"""
ğŸ¤– AI AUTO-APPLICATION CAMPAIGN COMPLETE
{'='*70}
â±ï¸  Duration: {results['campaign_duration']}
ğŸ“Š Jobs Analyzed: {stats['jobs_analyzed']}
ğŸ¯ High-Relevance Jobs: {stats['high_relevance_jobs']}
ğŸ“§ Emails Discovered: {stats['emails_discovered']}  
âœ‰ï¸  Applications Sent: {stats['applications_sent']}

ğŸ“ˆ CAMPAIGN METRICS:
   â€¢ Job Relevance Filter: {self.min_job_relevance_score}% minimum
   â€¢ Email Confidence Filter: {self.min_email_confidence}% minimum
   â€¢ Success Rate: {(stats['applications_sent']/max(stats['high_relevance_jobs'], 1)*100):.1f}%
   â€¢ Automation Level: 100% (Fully AI-powered)

ğŸ¯ EXPECTED RESULTS:
   â€¢ Estimated Responses: {max(1, stats['applications_sent'] // 7)} replies
   â€¢ Interview Probability: {max(1, stats['applications_sent'] // 15)} interviews
   â€¢ Timeline: 1-2 weeks for initial responses

ğŸš€ NEXT STEPS:
   1. Monitor email responses in your inbox
   2. Check data/ folder for detailed analytics  
   3. Run again tomorrow for fresh opportunities
   4. Review AI insights in campaign results file

{'='*70}
ğŸ¤– Powered by AI Job Automation Suite
"""
        
        return summary


def main():
    """Main function to run automated job application campaign."""
    try:
        # Initialize AI Auto-Application Engine
        engine = AIAutoApplicationEngine(max_applications_per_day=25)
        
        print("ğŸ¤– AI AUTO-APPLICATION ENGINE")
        print("="*50)
        print("This will automatically:")
        print("â€¢ Find relevant job opportunities")  
        print("â€¢ Generate personalized applications")
        print("â€¢ Send AI-optimized emails")
        print("â€¢ Track and analyze results")
        print()
        
        # Run automated campaign
        results = engine.run_automated_application_campaign()
        
        print("\\nâœ… AUTOMATED CAMPAIGN COMPLETE!")
        print("Check data/ folder for detailed results and analytics.")
        
        return results
        
    except Exception as e:
        logging.error(f"âŒ Auto-application engine failed: {e}")
        return {'error': str(e)}


if __name__ == "__main__":
    main()